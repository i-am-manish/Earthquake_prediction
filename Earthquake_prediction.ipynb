{
  "cells": [
    {
      "metadata": {
        "_uuid": "80f28a6efc7c4b5298c077a70c7d539b2a8dbebd"
      },
      "cell_type": "raw",
      "source": ""
    },
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "_kg_hide-input": true,
        "_kg_hide-output": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set()",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a54c08442e5f9f59067da2fa0a44ed1c8040fd99"
      },
      "cell_type": "code",
      "source": "data = pd.read_csv(\"../input/train.csv\",dtype={\"acoustic_data\": np.float32, \"time_to_failure\": np.float32}) #data is of 8.6GB, so nrows needs to be set\ndata.head(10)\n#acoustic_data=signal & time_to_failure=quaketime",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "   acoustic_data  time_to_failure\n0           12.0           1.4691\n1            6.0           1.4691\n2            8.0           1.4691\n3            5.0           1.4691\n4            8.0           1.4691\n5            8.0           1.4691\n6            9.0           1.4691\n7            7.0           1.4691\n8           -5.0           1.4691\n9            3.0           1.4691",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acoustic_data</th>\n      <th>time_to_failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>6.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>8.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>9.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-5.0</td>\n      <td>1.4691</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>3.0</td>\n      <td>1.4691</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4e1c6b0a6ca516c4817eb32fad4b4f6bf03de78c"
      },
      "cell_type": "code",
      "source": "#EDA # i'll take these features to train\ndata.describe()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "       acoustic_data  time_to_failure\ncount   6.291455e+08     6.291455e+08\nmean    7.371910e-01     4.477084e-01\nstd     9.818262e+00     2.612789e+00\nmin    -5.515000e+03     9.550396e-05\n25%     2.000000e+00     2.625997e+00\n50%     5.000000e+00     5.349798e+00\n75%     7.000000e+00     8.173395e+00\nmax     5.444000e+03     1.610740e+01",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>acoustic_data</th>\n      <th>time_to_failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>6.291455e+08</td>\n      <td>6.291455e+08</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>7.371910e-01</td>\n      <td>4.477084e-01</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>9.818262e+00</td>\n      <td>2.612789e+00</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>-5.515000e+03</td>\n      <td>9.550396e-05</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.000000e+00</td>\n      <td>2.625997e+00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>5.000000e+00</td>\n      <td>5.349798e+00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>7.000000e+00</td>\n      <td>8.173395e+00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>5.444000e+03</td>\n      <td>1.610740e+01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b80c09e401ea4eafa66f3aa68ada8ef724a96933"
      },
      "cell_type": "code",
      "source": "data.shape",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "(629145480, 2)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "db4c24f3663559ca5f66e655ca414c9ed4f3b831"
      },
      "cell_type": "code",
      "source": "#make learnable features (empty yet)\nnrows=200000\nsets = int(np.floor(data.shape[0] / nrows))\n\nX_train = pd.DataFrame(index=range(sets),columns = ['mean','std','min-0quat','25quat','50quat','75quat','max-1quat'])\ny_train = pd.DataFrame(index=range(sets),columns = ['time_to_failure'])",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "363dc9900b40b2436319b137e12d0e43ac079228"
      },
      "cell_type": "code",
      "source": "X_train.head()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "  mean  std min-0quat 25quat 50quat 75quat max-1quat\n0  NaN  NaN       NaN    NaN    NaN    NaN       NaN\n1  NaN  NaN       NaN    NaN    NaN    NaN       NaN\n2  NaN  NaN       NaN    NaN    NaN    NaN       NaN\n3  NaN  NaN       NaN    NaN    NaN    NaN       NaN\n4  NaN  NaN       NaN    NaN    NaN    NaN       NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min-0quat</th>\n      <th>25quat</th>\n      <th>50quat</th>\n      <th>75quat</th>\n      <th>max-1quat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "49ac227a6c8985473130709f9d108e4f57594a4b"
      },
      "cell_type": "code",
      "source": "y_train.head()",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "  time_to_failure\n0             NaN\n1             NaN\n2             NaN\n3             NaN\n4             NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a27d264c150cc7f698f7005c7a4ac7607ab3fe40"
      },
      "cell_type": "code",
      "source": "#filling the tables\nfor set in (range(sets)):   #tqdm(range(sets))\n    x=data.iloc[set*nrows:set*nrows+nrows]       #s.iloc[:3] returns us the first 3 rows (since it treats 3 as a position) and s.loc[:3] returns us the first 8 rows (since it treats 3 as a label)\n    y = x['time_to_failure'].values[-1]\n    x = x['acoustic_data'].values\n    #adding mean,max,std to their respective columns(features)\n    X_train.loc[set,'mean']=np.mean(x)\n    X_train.loc[set,'std']=np.std(x)\n    X_train.loc[set,'min-0quat']=np.quantile(x,0.01)\n    X_train.loc[set,'25quat']=np.quantile(x,0.25)\n    X_train.loc[set,'50quat']=np.quantile(x,0.5)\n    X_train.loc[set,'75quat']=np.quantile(x,0.75)\n    X_train.loc[set,'max-1quat']=np.quantile(x,0.99)\n    y_train.loc[set,'time_to_failure'] = y\n    ",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a7813afb6c9fea0b27402384cc8df78d5f744882"
      },
      "cell_type": "code",
      "source": "X_train.head(5)",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 9,
          "data": {
            "text/plain": "      mean      std min-0quat 25quat 50quat 75quat max-1quat\n0  4.83769  5.73268        -9      2      5      7        19\n1  4.77767  6.09176       -11      2      5      7        21\n2  4.94853  7.37905       -14      2      5      7        24\n3  4.94923  6.70204       -12      3      5      7        23\n4  4.86812  5.84906       -12      2      5      7        21",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min-0quat</th>\n      <th>25quat</th>\n      <th>50quat</th>\n      <th>75quat</th>\n      <th>max-1quat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.83769</td>\n      <td>5.73268</td>\n      <td>-9</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>19</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4.77767</td>\n      <td>6.09176</td>\n      <td>-11</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4.94853</td>\n      <td>7.37905</td>\n      <td>-14</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>24</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4.94923</td>\n      <td>6.70204</td>\n      <td>-12</td>\n      <td>3</td>\n      <td>5</td>\n      <td>7</td>\n      <td>23</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.86812</td>\n      <td>5.84906</td>\n      <td>-12</td>\n      <td>2</td>\n      <td>5</td>\n      <td>7</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "347cf48c8ee4fbd6983a324541e9537550029b93"
      },
      "cell_type": "code",
      "source": "y_train.head(5)",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 10,
          "data": {
            "text/plain": "  time_to_failure\n0          1.4181\n1          1.3659\n2          1.3138\n3          1.2617\n4          1.2095",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_failure</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.4181</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.3659</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.3138</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.2617</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1.2095</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "48feca106983facd73743a2d826e1879408b4d2f"
      },
      "cell_type": "code",
      "source": "from sklearn.preprocessing import StandardScaler\n#it will transform your data such that its distribution will have a mean value 0 and standard deviation of 1.\n#Given the distribution of the data, each value in the dataset will have the sample mean value subtracted,\n#and then divided by the standard deviation of the whole dataset.\nscaler=StandardScaler()\nX_scaled=scaler.fit_transform(X_train)",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/data.py:625: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n  return self.partial_fit(X, y)\n/opt/conda/lib/python3.6/site-packages/sklearn/base.py:462: DataConversionWarning: Data with input dtype object were all converted to float64 by StandardScaler.\n  return self.fit(X, **fit_params).transform(X)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "a071c76e20bc8765c23060b0884bac9fc62ba3fe"
      },
      "cell_type": "code",
      "source": "from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\n\n\nmodel=Sequential()\nmodel.add(Dense(32,input_shape=(7,),activation = \"relu\"))\nmodel.add(Dense(32,activation=\"relu\"))\nmodel.add(Dense(32,activation=\"relu\"))\nmodel.add(Dense(1))\nadam=Adam(lr=0.0001)\nmodel.compile(loss=\"mae\",optimizer=adam)\n\nmodel.fit(X_scaled,y_train,epochs = 500,validation_split=0.2)#batch_size",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Train on 2516 samples, validate on 629 samples\nEpoch 1/500\n2516/2516 [==============================] - 3s 1ms/step - loss: 5.5664 - val_loss: 5.8672\nEpoch 2/500\n2516/2516 [==============================] - 0s 133us/step - loss: 5.3855 - val_loss: 5.6437\nEpoch 3/500\n2516/2516 [==============================] - 0s 131us/step - loss: 5.1776 - val_loss: 5.3473\nEpoch 4/500\n2516/2516 [==============================] - 0s 131us/step - loss: 4.9145 - val_loss: 4.9408\nEpoch 5/500\n2516/2516 [==============================] - 0s 131us/step - loss: 4.5588 - val_loss: 4.3718\nEpoch 6/500\n2516/2516 [==============================] - 0s 128us/step - loss: 4.0880 - val_loss: 3.6928\nEpoch 7/500\n2516/2516 [==============================] - 0s 129us/step - loss: 3.5703 - val_loss: 3.0874\nEpoch 8/500\n2516/2516 [==============================] - 0s 138us/step - loss: 3.0448 - val_loss: 2.7395\nEpoch 9/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.6389 - val_loss: 2.6313\nEpoch 10/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.4254 - val_loss: 2.5864\nEpoch 11/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.3089 - val_loss: 2.5780\nEpoch 12/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.2553 - val_loss: 2.5639\nEpoch 13/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.2254 - val_loss: 2.5622\nEpoch 14/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.2015 - val_loss: 2.5597\nEpoch 15/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.1814 - val_loss: 2.5535\nEpoch 16/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.1634 - val_loss: 2.5455\nEpoch 17/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.1482 - val_loss: 2.5414\nEpoch 18/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.1357 - val_loss: 2.5397\nEpoch 19/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.1241 - val_loss: 2.5376\nEpoch 20/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.1147 - val_loss: 2.5403\nEpoch 21/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.1064 - val_loss: 2.5354\nEpoch 22/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0990 - val_loss: 2.5384\nEpoch 23/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0931 - val_loss: 2.5361\nEpoch 24/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0871 - val_loss: 2.5377\nEpoch 25/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0814 - val_loss: 2.5413\nEpoch 26/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0770 - val_loss: 2.5338\nEpoch 27/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0736 - val_loss: 2.5317\nEpoch 28/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0706 - val_loss: 2.5318\nEpoch 29/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0678 - val_loss: 2.5295\nEpoch 30/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0646 - val_loss: 2.5281\nEpoch 31/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0628 - val_loss: 2.5229\nEpoch 32/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0609 - val_loss: 2.5141\nEpoch 33/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0600 - val_loss: 2.5196\nEpoch 34/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0574 - val_loss: 2.5187\nEpoch 35/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0573 - val_loss: 2.5233\nEpoch 36/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0557 - val_loss: 2.5313\nEpoch 37/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0543 - val_loss: 2.5166\nEpoch 38/500\n2516/2516 [==============================] - 0s 147us/step - loss: 2.0530 - val_loss: 2.5180\nEpoch 39/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0517 - val_loss: 2.5227\nEpoch 40/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0514 - val_loss: 2.5192\nEpoch 41/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0508 - val_loss: 2.5232\nEpoch 42/500\n2516/2516 [==============================] - 0s 153us/step - loss: 2.0502 - val_loss: 2.5240\nEpoch 43/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0494 - val_loss: 2.5237\nEpoch 44/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0487 - val_loss: 2.5262\nEpoch 45/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0480 - val_loss: 2.5263\nEpoch 46/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0471 - val_loss: 2.5233\nEpoch 47/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0468 - val_loss: 2.5204\nEpoch 48/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0464 - val_loss: 2.5193\nEpoch 49/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0455 - val_loss: 2.5235\nEpoch 50/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0453 - val_loss: 2.5177\nEpoch 51/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0455 - val_loss: 2.5155\nEpoch 52/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0455 - val_loss: 2.5282\nEpoch 53/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0447 - val_loss: 2.5298\nEpoch 54/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0435 - val_loss: 2.5157\nEpoch 55/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0433 - val_loss: 2.5191\nEpoch 56/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0436 - val_loss: 2.5115\nEpoch 57/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0433 - val_loss: 2.5194\nEpoch 58/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0423 - val_loss: 2.5210\nEpoch 59/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0417 - val_loss: 2.5192\nEpoch 60/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0423 - val_loss: 2.5168\nEpoch 61/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0408 - val_loss: 2.5247\nEpoch 62/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0410 - val_loss: 2.5159\nEpoch 63/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0404 - val_loss: 2.5137\nEpoch 64/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0408 - val_loss: 2.5262\nEpoch 65/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0404 - val_loss: 2.5241\nEpoch 66/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0400 - val_loss: 2.5143\nEpoch 67/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0402 - val_loss: 2.5179\nEpoch 68/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0382 - val_loss: 2.5163\nEpoch 69/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0380 - val_loss: 2.5191\nEpoch 70/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0383 - val_loss: 2.5194\nEpoch 71/500\n2516/2516 [==============================] - 0s 147us/step - loss: 2.0383 - val_loss: 2.5231\nEpoch 72/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0380 - val_loss: 2.5088\nEpoch 73/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0369 - val_loss: 2.5168\nEpoch 74/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0371 - val_loss: 2.5219\nEpoch 75/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0365 - val_loss: 2.5167\nEpoch 76/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0371 - val_loss: 2.5115\nEpoch 77/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0362 - val_loss: 2.5193\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 78/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0366 - val_loss: 2.5175\nEpoch 79/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0358 - val_loss: 2.5238\nEpoch 80/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0358 - val_loss: 2.5182\nEpoch 81/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0350 - val_loss: 2.5144\nEpoch 82/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0352 - val_loss: 2.5194\nEpoch 83/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0358 - val_loss: 2.5273\nEpoch 84/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0347 - val_loss: 2.5229\nEpoch 85/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0349 - val_loss: 2.5271\nEpoch 86/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0345 - val_loss: 2.5203\nEpoch 87/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0336 - val_loss: 2.5226\nEpoch 88/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0330 - val_loss: 2.5188\nEpoch 89/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0331 - val_loss: 2.5169\nEpoch 90/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0325 - val_loss: 2.5240\nEpoch 91/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0338 - val_loss: 2.5206\nEpoch 92/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0344 - val_loss: 2.5205\nEpoch 93/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0326 - val_loss: 2.5228\nEpoch 94/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0322 - val_loss: 2.5186\nEpoch 95/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0318 - val_loss: 2.5239\nEpoch 96/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0320 - val_loss: 2.5183\nEpoch 97/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0315 - val_loss: 2.5244\nEpoch 98/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0318 - val_loss: 2.5188\nEpoch 99/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0318 - val_loss: 2.5179\nEpoch 100/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0305 - val_loss: 2.5204\nEpoch 101/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0307 - val_loss: 2.5246\nEpoch 102/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0299 - val_loss: 2.5236\nEpoch 103/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0312 - val_loss: 2.5293\nEpoch 104/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0313 - val_loss: 2.5261\nEpoch 105/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0306 - val_loss: 2.5250\nEpoch 106/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0300 - val_loss: 2.5257\nEpoch 107/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0297 - val_loss: 2.5238\nEpoch 108/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0296 - val_loss: 2.5175\nEpoch 109/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0294 - val_loss: 2.5172\nEpoch 110/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0288 - val_loss: 2.5245\nEpoch 111/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0296 - val_loss: 2.5217\nEpoch 112/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0291 - val_loss: 2.5295\nEpoch 113/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0310 - val_loss: 2.5198\nEpoch 114/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0293 - val_loss: 2.5200\nEpoch 115/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0279 - val_loss: 2.5244\nEpoch 116/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0296 - val_loss: 2.5279\nEpoch 117/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0280 - val_loss: 2.5246\nEpoch 118/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0279 - val_loss: 2.5287\nEpoch 119/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0279 - val_loss: 2.5279\nEpoch 120/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0294 - val_loss: 2.5192\nEpoch 121/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0281 - val_loss: 2.5243\nEpoch 122/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0284 - val_loss: 2.5296\nEpoch 123/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0279 - val_loss: 2.5216\nEpoch 124/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0276 - val_loss: 2.5308\nEpoch 125/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0268 - val_loss: 2.5226\nEpoch 126/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0273 - val_loss: 2.5251\nEpoch 127/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0270 - val_loss: 2.5277\nEpoch 128/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0280 - val_loss: 2.5221\nEpoch 129/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0265 - val_loss: 2.5301\nEpoch 130/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0269 - val_loss: 2.5275\nEpoch 131/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0264 - val_loss: 2.5332\nEpoch 132/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0266 - val_loss: 2.5237\nEpoch 133/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0253 - val_loss: 2.5311\nEpoch 134/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0264 - val_loss: 2.5265\nEpoch 135/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0260 - val_loss: 2.5323\nEpoch 136/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0261 - val_loss: 2.5343\nEpoch 137/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0253 - val_loss: 2.5299\nEpoch 138/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0253 - val_loss: 2.5298\nEpoch 139/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0261 - val_loss: 2.5255\nEpoch 140/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0256 - val_loss: 2.5343\nEpoch 141/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0256 - val_loss: 2.5298\nEpoch 142/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0250 - val_loss: 2.5308\nEpoch 143/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0250 - val_loss: 2.5245\nEpoch 144/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0260 - val_loss: 2.5330\nEpoch 145/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0245 - val_loss: 2.5324\nEpoch 146/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0248 - val_loss: 2.5301\nEpoch 147/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0244 - val_loss: 2.5323\nEpoch 148/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0241 - val_loss: 2.5325\nEpoch 149/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0241 - val_loss: 2.5348\nEpoch 150/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0240 - val_loss: 2.5291\nEpoch 151/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0238 - val_loss: 2.5350\nEpoch 152/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0248 - val_loss: 2.5349\nEpoch 153/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0246 - val_loss: 2.5336\nEpoch 154/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0234 - val_loss: 2.5320\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "Epoch 155/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0237 - val_loss: 2.5350\nEpoch 156/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0237 - val_loss: 2.5307\nEpoch 157/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0265 - val_loss: 2.5315\nEpoch 158/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0250 - val_loss: 2.5446\nEpoch 159/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0228 - val_loss: 2.5356\nEpoch 160/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0223 - val_loss: 2.5338\nEpoch 161/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0231 - val_loss: 2.5419\nEpoch 162/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0224 - val_loss: 2.5401\nEpoch 163/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0232 - val_loss: 2.5423\nEpoch 164/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0223 - val_loss: 2.5388\nEpoch 165/500\n2516/2516 [==============================] - 0s 148us/step - loss: 2.0223 - val_loss: 2.5342\nEpoch 166/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0219 - val_loss: 2.5377\nEpoch 167/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0226 - val_loss: 2.5368\nEpoch 168/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0232 - val_loss: 2.5416\nEpoch 169/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0215 - val_loss: 2.5377\nEpoch 170/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0222 - val_loss: 2.5394\nEpoch 171/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0215 - val_loss: 2.5425\nEpoch 172/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0216 - val_loss: 2.5430\nEpoch 173/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0212 - val_loss: 2.5454\nEpoch 174/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0213 - val_loss: 2.5373\nEpoch 175/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0221 - val_loss: 2.5402\nEpoch 176/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0211 - val_loss: 2.5477\nEpoch 177/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0216 - val_loss: 2.5484\nEpoch 178/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0215 - val_loss: 2.5365\nEpoch 179/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0213 - val_loss: 2.5427\nEpoch 180/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0205 - val_loss: 2.5415\nEpoch 181/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0201 - val_loss: 2.5428\nEpoch 182/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0217 - val_loss: 2.5471\nEpoch 183/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0207 - val_loss: 2.5452\nEpoch 184/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0208 - val_loss: 2.5504\nEpoch 185/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0211 - val_loss: 2.5510\nEpoch 186/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0202 - val_loss: 2.5440\nEpoch 187/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0207 - val_loss: 2.5396\nEpoch 188/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0197 - val_loss: 2.5467\nEpoch 189/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0206 - val_loss: 2.5499\nEpoch 190/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0197 - val_loss: 2.5483\nEpoch 191/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0219 - val_loss: 2.5415\nEpoch 192/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0210 - val_loss: 2.5463\nEpoch 193/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0203 - val_loss: 2.5517\nEpoch 194/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0197 - val_loss: 2.5503\nEpoch 195/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0200 - val_loss: 2.5364\nEpoch 196/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0198 - val_loss: 2.5411\nEpoch 197/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0203 - val_loss: 2.5541\nEpoch 198/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0195 - val_loss: 2.5524\nEpoch 199/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0195 - val_loss: 2.5472\nEpoch 200/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0187 - val_loss: 2.5519\nEpoch 201/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0194 - val_loss: 2.5553\nEpoch 202/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0191 - val_loss: 2.5558\nEpoch 203/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0186 - val_loss: 2.5568\nEpoch 204/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0185 - val_loss: 2.5543\nEpoch 205/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0190 - val_loss: 2.5597\nEpoch 206/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0188 - val_loss: 2.5519\nEpoch 207/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0190 - val_loss: 2.5497\nEpoch 208/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0183 - val_loss: 2.5538\nEpoch 209/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0190 - val_loss: 2.5492\nEpoch 210/500\n2516/2516 [==============================] - 0s 154us/step - loss: 2.0189 - val_loss: 2.5451\nEpoch 211/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0190 - val_loss: 2.5450\nEpoch 212/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0189 - val_loss: 2.5491\nEpoch 213/500\n2516/2516 [==============================] - 0s 147us/step - loss: 2.0182 - val_loss: 2.5476\nEpoch 214/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0184 - val_loss: 2.5492\nEpoch 215/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0178 - val_loss: 2.5451\nEpoch 216/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0188 - val_loss: 2.5578\nEpoch 217/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0187 - val_loss: 2.5479\nEpoch 218/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0177 - val_loss: 2.5502\nEpoch 219/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0171 - val_loss: 2.5621\nEpoch 220/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0184 - val_loss: 2.5569\nEpoch 221/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0176 - val_loss: 2.5618\nEpoch 222/500\n2516/2516 [==============================] - 0s 135us/step - loss: 2.0172 - val_loss: 2.5567\nEpoch 223/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0170 - val_loss: 2.5573\nEpoch 224/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0176 - val_loss: 2.5597\nEpoch 225/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0172 - val_loss: 2.5522\nEpoch 226/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0177 - val_loss: 2.5577\nEpoch 227/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0167 - val_loss: 2.5531\nEpoch 228/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0167 - val_loss: 2.5673\nEpoch 229/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0180 - val_loss: 2.5577\nEpoch 230/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0172 - val_loss: 2.5574\nEpoch 231/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "2516/2516 [==============================] - 0s 143us/step - loss: 2.0170 - val_loss: 2.5597\nEpoch 232/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0176 - val_loss: 2.5646\nEpoch 233/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0167 - val_loss: 2.5522\nEpoch 234/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0171 - val_loss: 2.5570\nEpoch 235/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0159 - val_loss: 2.5526\nEpoch 236/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0158 - val_loss: 2.5576\nEpoch 237/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0163 - val_loss: 2.5550\nEpoch 238/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0161 - val_loss: 2.5697\nEpoch 239/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0167 - val_loss: 2.5653\nEpoch 240/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0173 - val_loss: 2.5675\nEpoch 241/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0175 - val_loss: 2.5642\nEpoch 242/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0160 - val_loss: 2.5656\nEpoch 243/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0153 - val_loss: 2.5640\nEpoch 244/500\n2516/2516 [==============================] - 0s 147us/step - loss: 2.0152 - val_loss: 2.5631\nEpoch 245/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0146 - val_loss: 2.5690\nEpoch 246/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0175 - val_loss: 2.5639\nEpoch 247/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0162 - val_loss: 2.5618\nEpoch 248/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0157 - val_loss: 2.5645\nEpoch 249/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0151 - val_loss: 2.5661\nEpoch 250/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0154 - val_loss: 2.5726\nEpoch 251/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0155 - val_loss: 2.5668\nEpoch 252/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0145 - val_loss: 2.5716\nEpoch 253/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0155 - val_loss: 2.5698\nEpoch 254/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0165 - val_loss: 2.5644\nEpoch 255/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0150 - val_loss: 2.5688\nEpoch 256/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0150 - val_loss: 2.5679\nEpoch 257/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0140 - val_loss: 2.5693\nEpoch 258/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0141 - val_loss: 2.5701\nEpoch 259/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0153 - val_loss: 2.5710\nEpoch 260/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0143 - val_loss: 2.5729\nEpoch 261/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0145 - val_loss: 2.5744\nEpoch 262/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0138 - val_loss: 2.5811\nEpoch 263/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0139 - val_loss: 2.5697\nEpoch 264/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0146 - val_loss: 2.5727\nEpoch 265/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0141 - val_loss: 2.5643\nEpoch 266/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0139 - val_loss: 2.5770\nEpoch 267/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0136 - val_loss: 2.5644\nEpoch 268/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0142 - val_loss: 2.5730\nEpoch 269/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0142 - val_loss: 2.5702\nEpoch 270/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0137 - val_loss: 2.5720\nEpoch 271/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0135 - val_loss: 2.5800\nEpoch 272/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0131 - val_loss: 2.5672\nEpoch 273/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0143 - val_loss: 2.5748\nEpoch 274/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0138 - val_loss: 2.5752\nEpoch 275/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0138 - val_loss: 2.5852\nEpoch 276/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0131 - val_loss: 2.5806\nEpoch 277/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0131 - val_loss: 2.5795\nEpoch 278/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0124 - val_loss: 2.5755\nEpoch 279/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0126 - val_loss: 2.5770\nEpoch 280/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0131 - val_loss: 2.5815\nEpoch 281/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0141 - val_loss: 2.5721\nEpoch 282/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0123 - val_loss: 2.5824\nEpoch 283/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0122 - val_loss: 2.5784\nEpoch 284/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0128 - val_loss: 2.5775\nEpoch 285/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0119 - val_loss: 2.5852\nEpoch 286/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0132 - val_loss: 2.5829\nEpoch 287/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0120 - val_loss: 2.5796\nEpoch 288/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0121 - val_loss: 2.5804\nEpoch 289/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0133 - val_loss: 2.5809\nEpoch 290/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0129 - val_loss: 2.5825\nEpoch 291/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0122 - val_loss: 2.5820\nEpoch 292/500\n2516/2516 [==============================] - 0s 148us/step - loss: 2.0125 - val_loss: 2.5847\nEpoch 293/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0116 - val_loss: 2.5771\nEpoch 294/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0121 - val_loss: 2.5771\nEpoch 295/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0118 - val_loss: 2.5771\nEpoch 296/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0118 - val_loss: 2.5851\nEpoch 297/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0124 - val_loss: 2.5902\nEpoch 298/500\n2516/2516 [==============================] - 0s 134us/step - loss: 2.0119 - val_loss: 2.5934\nEpoch 299/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0120 - val_loss: 2.5835\nEpoch 300/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0126 - val_loss: 2.5857\nEpoch 301/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0102 - val_loss: 2.5897\nEpoch 302/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0109 - val_loss: 2.5935\nEpoch 303/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0110 - val_loss: 2.5829\nEpoch 304/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0118 - val_loss: 2.5807\nEpoch 305/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0099 - val_loss: 2.5861\nEpoch 306/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0106 - val_loss: 2.5877\nEpoch 307/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "2516/2516 [==============================] - 0s 138us/step - loss: 2.0107 - val_loss: 2.5918\nEpoch 308/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0099 - val_loss: 2.5921\nEpoch 309/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0103 - val_loss: 2.5922\nEpoch 310/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0105 - val_loss: 2.5944\nEpoch 311/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0105 - val_loss: 2.5883\nEpoch 312/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0096 - val_loss: 2.5856\nEpoch 313/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0110 - val_loss: 2.5943\nEpoch 314/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0094 - val_loss: 2.5857\nEpoch 315/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0095 - val_loss: 2.5876\nEpoch 316/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0107 - val_loss: 2.5945\nEpoch 317/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0104 - val_loss: 2.5934\nEpoch 318/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0090 - val_loss: 2.5909\nEpoch 319/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0092 - val_loss: 2.5929\nEpoch 320/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0092 - val_loss: 2.5987\nEpoch 321/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0090 - val_loss: 2.5953\nEpoch 322/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0092 - val_loss: 2.5972\nEpoch 323/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0102 - val_loss: 2.5928\nEpoch 324/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0084 - val_loss: 2.5963\nEpoch 325/500\n2516/2516 [==============================] - 0s 146us/step - loss: 2.0093 - val_loss: 2.6012\nEpoch 326/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0080 - val_loss: 2.5966\nEpoch 327/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0096 - val_loss: 2.5925\nEpoch 328/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0090 - val_loss: 2.5916\nEpoch 329/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0083 - val_loss: 2.5900\nEpoch 330/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0084 - val_loss: 2.5945\nEpoch 331/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0081 - val_loss: 2.6004\nEpoch 332/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0081 - val_loss: 2.5997\nEpoch 333/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0072 - val_loss: 2.6105\nEpoch 334/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0083 - val_loss: 2.6000\nEpoch 335/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0087 - val_loss: 2.5920\nEpoch 336/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0077 - val_loss: 2.6020\nEpoch 337/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0073 - val_loss: 2.5988\nEpoch 338/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0078 - val_loss: 2.6035\nEpoch 339/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0070 - val_loss: 2.5978\nEpoch 340/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0070 - val_loss: 2.6045\nEpoch 341/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0069 - val_loss: 2.6102\nEpoch 342/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0072 - val_loss: 2.6027\nEpoch 343/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0067 - val_loss: 2.6015\nEpoch 344/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0075 - val_loss: 2.5965\nEpoch 345/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0076 - val_loss: 2.5968\nEpoch 346/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0059 - val_loss: 2.6052\nEpoch 347/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0063 - val_loss: 2.6070\nEpoch 348/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0075 - val_loss: 2.5994\nEpoch 349/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0071 - val_loss: 2.6058\nEpoch 350/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0067 - val_loss: 2.5997\nEpoch 351/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0066 - val_loss: 2.6111\nEpoch 352/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0062 - val_loss: 2.6014\nEpoch 353/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0059 - val_loss: 2.6072\nEpoch 354/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0076 - val_loss: 2.6072\nEpoch 355/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0066 - val_loss: 2.6104\nEpoch 356/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0066 - val_loss: 2.6189\nEpoch 357/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0075 - val_loss: 2.6170\nEpoch 358/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0060 - val_loss: 2.6052\nEpoch 359/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0066 - val_loss: 2.6092\nEpoch 360/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0058 - val_loss: 2.6146\nEpoch 361/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0056 - val_loss: 2.6083\nEpoch 362/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0057 - val_loss: 2.6065\nEpoch 363/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0056 - val_loss: 2.6138\nEpoch 364/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0062 - val_loss: 2.6129\nEpoch 365/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0055 - val_loss: 2.6124\nEpoch 366/500\n2516/2516 [==============================] - 0s 135us/step - loss: 2.0058 - val_loss: 2.6096\nEpoch 367/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0054 - val_loss: 2.6017\nEpoch 368/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0049 - val_loss: 2.6163\nEpoch 369/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0051 - val_loss: 2.6170\nEpoch 370/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0042 - val_loss: 2.6122\nEpoch 371/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0051 - val_loss: 2.6134\nEpoch 372/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0056 - val_loss: 2.6054\nEpoch 373/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0055 - val_loss: 2.6178\nEpoch 374/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0046 - val_loss: 2.6193\nEpoch 375/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0047 - val_loss: 2.6151\nEpoch 376/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0052 - val_loss: 2.6206\nEpoch 377/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0046 - val_loss: 2.6144\nEpoch 378/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0052 - val_loss: 2.6152\nEpoch 379/500\n2516/2516 [==============================] - 0s 151us/step - loss: 2.0040 - val_loss: 2.6212\nEpoch 380/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0045 - val_loss: 2.6242\nEpoch 381/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0041 - val_loss: 2.6183\nEpoch 382/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0039 - val_loss: 2.6232\nEpoch 383/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "2516/2516 [==============================] - 0s 141us/step - loss: 2.0055 - val_loss: 2.6246\nEpoch 384/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0040 - val_loss: 2.6140\nEpoch 385/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0036 - val_loss: 2.6226\nEpoch 386/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0041 - val_loss: 2.6274\nEpoch 387/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0037 - val_loss: 2.6235\nEpoch 388/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0038 - val_loss: 2.6244\nEpoch 389/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0061 - val_loss: 2.6160\nEpoch 390/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0034 - val_loss: 2.6296\nEpoch 391/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0034 - val_loss: 2.6234\nEpoch 392/500\n2516/2516 [==============================] - 0s 135us/step - loss: 2.0038 - val_loss: 2.6168\nEpoch 393/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0050 - val_loss: 2.6271\nEpoch 394/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0039 - val_loss: 2.6281\nEpoch 395/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0034 - val_loss: 2.6330\nEpoch 396/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0034 - val_loss: 2.6313\nEpoch 397/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0031 - val_loss: 2.6296\nEpoch 398/500\n2516/2516 [==============================] - 0s 143us/step - loss: 2.0038 - val_loss: 2.6258\nEpoch 399/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0043 - val_loss: 2.6251\nEpoch 400/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0037 - val_loss: 2.6277\nEpoch 401/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0044 - val_loss: 2.6305\nEpoch 402/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0037 - val_loss: 2.6339\nEpoch 403/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0027 - val_loss: 2.6268\nEpoch 404/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0027 - val_loss: 2.6263\nEpoch 405/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0031 - val_loss: 2.6299\nEpoch 406/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0039 - val_loss: 2.6354\nEpoch 407/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0033 - val_loss: 2.6428\nEpoch 408/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0028 - val_loss: 2.6326\nEpoch 409/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0025 - val_loss: 2.6388\nEpoch 410/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0023 - val_loss: 2.6302\nEpoch 411/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0028 - val_loss: 2.6395\nEpoch 412/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0033 - val_loss: 2.6383\nEpoch 413/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0027 - val_loss: 2.6417\nEpoch 414/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0033 - val_loss: 2.6319\nEpoch 415/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0027 - val_loss: 2.6378\nEpoch 416/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0027 - val_loss: 2.6337\nEpoch 417/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0030 - val_loss: 2.6252\nEpoch 418/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0015 - val_loss: 2.6337\nEpoch 419/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0015 - val_loss: 2.6364\nEpoch 420/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0020 - val_loss: 2.6367\nEpoch 421/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0025 - val_loss: 2.6368\nEpoch 422/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0027 - val_loss: 2.6368\nEpoch 423/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0022 - val_loss: 2.6384\nEpoch 424/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0021 - val_loss: 2.6343\nEpoch 425/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0010 - val_loss: 2.6371\nEpoch 426/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0012 - val_loss: 2.6404\nEpoch 427/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0021 - val_loss: 2.6340\nEpoch 428/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0013 - val_loss: 2.6424\nEpoch 429/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0012 - val_loss: 2.6429\nEpoch 430/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0018 - val_loss: 2.6420\nEpoch 431/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0005 - val_loss: 2.6429\nEpoch 432/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0008 - val_loss: 2.6436\nEpoch 433/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0005 - val_loss: 2.6472\nEpoch 434/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0015 - val_loss: 2.6465\nEpoch 435/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0014 - val_loss: 2.6334\nEpoch 436/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0010 - val_loss: 2.6435\nEpoch 437/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0020 - val_loss: 2.6461\nEpoch 438/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0006 - val_loss: 2.6501\nEpoch 439/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0006 - val_loss: 2.6583\nEpoch 440/500\n2516/2516 [==============================] - 0s 142us/step - loss: 2.0004 - val_loss: 2.6439\nEpoch 441/500\n2516/2516 [==============================] - 0s 144us/step - loss: 2.0000 - val_loss: 2.6523\nEpoch 442/500\n2516/2516 [==============================] - 0s 145us/step - loss: 2.0014 - val_loss: 2.6489\nEpoch 443/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0004 - val_loss: 2.6474\nEpoch 444/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0012 - val_loss: 2.6535\nEpoch 445/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0001 - val_loss: 2.6531\nEpoch 446/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0001 - val_loss: 2.6634\nEpoch 447/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9996 - val_loss: 2.6527\nEpoch 448/500\n2516/2516 [==============================] - 0s 137us/step - loss: 2.0001 - val_loss: 2.6449\nEpoch 449/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0014 - val_loss: 2.6449\nEpoch 450/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0005 - val_loss: 2.6574\nEpoch 451/500\n2516/2516 [==============================] - 0s 140us/step - loss: 2.0003 - val_loss: 2.6508\nEpoch 452/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0003 - val_loss: 2.6457\nEpoch 453/500\n2516/2516 [==============================] - 0s 141us/step - loss: 2.0006 - val_loss: 2.6491\nEpoch 454/500\n2516/2516 [==============================] - 0s 136us/step - loss: 1.9997 - val_loss: 2.6614\nEpoch 455/500\n2516/2516 [==============================] - 0s 134us/step - loss: 1.9997 - val_loss: 2.6526\nEpoch 456/500\n2516/2516 [==============================] - 0s 141us/step - loss: 1.9988 - val_loss: 2.6654\nEpoch 457/500\n2516/2516 [==============================] - 0s 139us/step - loss: 1.9994 - val_loss: 2.6582\nEpoch 458/500\n2516/2516 [==============================] - 0s 139us/step - loss: 2.0007 - val_loss: 2.6577\nEpoch 459/500\n",
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": "2516/2516 [==============================] - 0s 141us/step - loss: 2.0004 - val_loss: 2.6521\nEpoch 460/500\n2516/2516 [==============================] - 0s 138us/step - loss: 1.9988 - val_loss: 2.6700\nEpoch 461/500\n2516/2516 [==============================] - 0s 141us/step - loss: 1.9996 - val_loss: 2.6594\nEpoch 462/500\n2516/2516 [==============================] - 0s 138us/step - loss: 2.0011 - val_loss: 2.6522\nEpoch 463/500\n2516/2516 [==============================] - 0s 139us/step - loss: 1.9998 - val_loss: 2.6538\nEpoch 464/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9988 - val_loss: 2.6739\nEpoch 465/500\n2516/2516 [==============================] - 0s 136us/step - loss: 2.0000 - val_loss: 2.6725\nEpoch 466/500\n2516/2516 [==============================] - 0s 143us/step - loss: 1.9988 - val_loss: 2.6662\nEpoch 467/500\n2516/2516 [==============================] - 0s 144us/step - loss: 1.9991 - val_loss: 2.6718\nEpoch 468/500\n2516/2516 [==============================] - 0s 139us/step - loss: 1.9997 - val_loss: 2.6711\nEpoch 469/500\n2516/2516 [==============================] - 0s 135us/step - loss: 1.9986 - val_loss: 2.6700\nEpoch 470/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9986 - val_loss: 2.6639\nEpoch 471/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9991 - val_loss: 2.6643\nEpoch 472/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9985 - val_loss: 2.6709\nEpoch 473/500\n2516/2516 [==============================] - 0s 143us/step - loss: 1.9984 - val_loss: 2.6612\nEpoch 474/500\n2516/2516 [==============================] - 0s 141us/step - loss: 1.9995 - val_loss: 2.6772\nEpoch 475/500\n2516/2516 [==============================] - 0s 138us/step - loss: 1.9986 - val_loss: 2.6646\nEpoch 476/500\n2516/2516 [==============================] - 0s 136us/step - loss: 1.9981 - val_loss: 2.6818\nEpoch 477/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9984 - val_loss: 2.6660\nEpoch 478/500\n2516/2516 [==============================] - 0s 138us/step - loss: 1.9992 - val_loss: 2.6699\nEpoch 479/500\n2516/2516 [==============================] - 0s 137us/step - loss: 1.9985 - val_loss: 2.6671\nEpoch 480/500\n2516/2516 [==============================] - 0s 139us/step - loss: 1.9987 - val_loss: 2.6645\nEpoch 481/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9990 - val_loss: 2.6740\nEpoch 482/500\n2516/2516 [==============================] - 0s 138us/step - loss: 1.9994 - val_loss: 2.6841\nEpoch 483/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9979 - val_loss: 2.6693\nEpoch 484/500\n2516/2516 [==============================] - 0s 143us/step - loss: 1.9981 - val_loss: 2.6801\nEpoch 485/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9990 - val_loss: 2.6656\nEpoch 486/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9978 - val_loss: 2.6781\nEpoch 487/500\n2516/2516 [==============================] - 0s 144us/step - loss: 1.9982 - val_loss: 2.6742\nEpoch 488/500\n2516/2516 [==============================] - 0s 145us/step - loss: 1.9982 - val_loss: 2.6679\nEpoch 489/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9978 - val_loss: 2.6811\nEpoch 490/500\n2516/2516 [==============================] - 0s 145us/step - loss: 1.9976 - val_loss: 2.6742\nEpoch 491/500\n2516/2516 [==============================] - 0s 140us/step - loss: 1.9974 - val_loss: 2.6778\nEpoch 492/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9986 - val_loss: 2.6799\nEpoch 493/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9972 - val_loss: 2.6794\nEpoch 494/500\n2516/2516 [==============================] - 0s 144us/step - loss: 1.9974 - val_loss: 2.6784\nEpoch 495/500\n2516/2516 [==============================] - 0s 141us/step - loss: 1.9980 - val_loss: 2.6869\nEpoch 496/500\n2516/2516 [==============================] - 0s 142us/step - loss: 1.9974 - val_loss: 2.6810\nEpoch 497/500\n2516/2516 [==============================] - 0s 141us/step - loss: 1.9971 - val_loss: 2.6780\nEpoch 498/500\n2516/2516 [==============================] - 0s 144us/step - loss: 1.9982 - val_loss: 2.6829\nEpoch 499/500\n2516/2516 [==============================] - 0s 145us/step - loss: 1.9978 - val_loss: 2.6846\nEpoch 500/500\n2516/2516 [==============================] - 0s 143us/step - loss: 1.9972 - val_loss: 2.6890\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 13,
          "data": {
            "text/plain": "<keras.callbacks.History at 0x7ff047412ac8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55cd9fc337770ce2710f5c8ce1146dbd6ba279f4"
      },
      "cell_type": "code",
      "source": "submission_data = pd.read_csv('../input/sample_submission.csv',index_col = 'seg_id')\nsubmission_data.tail(5)\n",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "            time_to_failure\nseg_id                     \nseg_ff4236                0\nseg_ff7478                0\nseg_ff79d9                0\nseg_ffbd6a                0\nseg_ffe7cc                0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_failure</th>\n    </tr>\n    <tr>\n      <th>seg_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>seg_ff4236</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_ff7478</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_ff79d9</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_ffbd6a</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_ffe7cc</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "cc39ec805b1c84fd668319632e223f6c8846c16e"
      },
      "cell_type": "code",
      "source": "X_test = pd.DataFrame(columns = X_train.columns,dtype = np.float32,index=submission_data.index)\nX_test.head(4)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "            mean  std  min-0quat  25quat  50quat  75quat  max-1quat\nseg_id                                                             \nseg_00030f   NaN  NaN        NaN     NaN     NaN     NaN        NaN\nseg_0012b5   NaN  NaN        NaN     NaN     NaN     NaN        NaN\nseg_00184e   NaN  NaN        NaN     NaN     NaN     NaN        NaN\nseg_003339   NaN  NaN        NaN     NaN     NaN     NaN        NaN",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>std</th>\n      <th>min-0quat</th>\n      <th>25quat</th>\n      <th>50quat</th>\n      <th>75quat</th>\n      <th>max-1quat</th>\n    </tr>\n    <tr>\n      <th>seg_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>seg_00030f</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>seg_0012b5</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>seg_00184e</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>seg_003339</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "scrolled": true,
        "_uuid": "16fd1575e9d0ae5b35503d575dceba9f96461caa"
      },
      "cell_type": "code",
      "source": "from tqdm import tqdm\nfor seq in tqdm(X_test.index):\n    test_data = pd.read_csv('../input/test/'+seq+'.csv')\n    x = test_data['acoustic_data'].values\n    X_test.loc[seq,'mean'] = np.mean(x)\n    X_test.loc[seq,'std']  = np.std(x)\n    X_test.loc[set,'min-0quat']=np.quantile(x,0.01)\n    X_test.loc[set,'25quat']=np.quantile(x,0.25)\n    X_test.loc[set,'50quat']=np.quantile(x,0.5)\n    X_test.loc[set,'75quat']=np.quantile(x,0.75)\n    X_test.loc[set,'max-1quat']=np.quantile(x,0.99)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "100%|██████████| 2624/2624 [01:02<00:00, 41.79it/s]\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a830386384099fb4551f3878c91433e04cad70d"
      },
      "cell_type": "code",
      "source": "X_test_scaled = scaler.transform(X_test)\n#prediction\npred=model.predict(X_test_scaled)\n",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype float32 were all converted to float64 by StandardScaler.\n  \"\"\"Entry point for launching an IPython kernel.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b374854cdd663211d696f1fcd44d1ae1878ed761"
      },
      "cell_type": "code",
      "source": "print(submission_data.shape)\nsubmission_data.head()",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(2624, 1)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "            time_to_failure\nseg_id                     \nseg_00030f                0\nseg_0012b5                0\nseg_00184e                0\nseg_003339                0\nseg_0042cc                0",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>time_to_failure</th>\n    </tr>\n    <tr>\n      <th>seg_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>seg_00030f</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_0012b5</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_00184e</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_003339</th>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>seg_0042cc</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "870273a583e43b0817e733b041b69bc20118dae0",
        "scrolled": true
      },
      "cell_type": "code",
      "source": "print(pred.shape)\npred\n\n",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": "(2625, 1)\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 63,
          "data": {
            "text/plain": "array([[1.4410285],\n       [1.4410285],\n       [1.4410285],\n       ...,\n       [1.4410285],\n       [1.4410285],\n       [1.4410285]], dtype=float32)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c055b48447fd4f30ed9449f2bd7cc37be2f7510"
      },
      "cell_type": "code",
      "source": "submission_data['seg_id'] = submission_data.index\n",
      "execution_count": 66,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b70c07da7f3ce2901b3c822096960474c09e8095"
      },
      "cell_type": "code",
      "source": "pred=submission_data[\"time_to_failure\"]",
      "execution_count": 67,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a98789e5943a3e345f2b66c882f25f9914900385"
      },
      "cell_type": "code",
      "source": "submission_data.to_csv('sub_earthquake.csv',index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d65eb5731a98102d8e76904b650d62b357c97fdf"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}